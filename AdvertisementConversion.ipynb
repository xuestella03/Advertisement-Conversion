{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc46663-3e33-43e2-bf5f-7b02ab805b6b",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d74c08-4c92-4253-82b8-5b1d626806e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, mean_squared_error\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce166981-afaa-4b3e-a261-b225e93ba4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into dataframes\n",
    "df_conversion = pd.read_csv('Conversion_data.csv')\n",
    "df_nonconversion = pd.read_csv('nonconversion_data.csv')\n",
    "\n",
    "# add an additional column to label data as conversion or nonconversion\n",
    "df_conversion.insert(7, 'conversion?', [1] * len(df_conversion), True)\n",
    "df_nonconversion.insert(7, 'conversion?', [0] * len(df_nonconversion), True)\n",
    "\n",
    "# concat the two dataframes\n",
    "frames = [df_conversion, df_nonconversion]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# relabel the columns\n",
    "df.columns = ['Site', 'Format', 'Browser', 'Vendor', 'Metro', 'OS', 'Hours', 'Conversion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85aee8-3ba9-4084-bf04-dbecb7348dab",
   "metadata": {},
   "source": [
    "# Functions for Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ddc27e-d82a-4c0a-a531-131fa08de7f0",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e582de7-0b46-4cb5-bef9-4310433c5498",
   "metadata": {},
   "source": [
    "I labeled arguments as `numerical_var` to include data points that are not strictly continuous (such as Conversion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de33430-222d-40b7-93cd-e95d3865b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_stats(data, numerical_var):\n",
    "    \"\"\"\n",
    "    Generate descriptive statistics for continuous & numerical variables\n",
    "\n",
    "    Args:\n",
    "        data (dataframe): the dataframe with the data\n",
    "        numerical_var (string): the numerical var you want stats for\n",
    "\n",
    "    Returns:\n",
    "        dataframe with mean, median, std dev, skew, and kurtosis\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate stats\n",
    "    mean = data[numerical_var].mean()\n",
    "    median = data[numerical_var].median()\n",
    "    std_dev = data[numerical_var].std()\n",
    "    skew = data[numerical_var].skew()\n",
    "    kurtosis = data[numerical_var].kurtosis()\n",
    "\n",
    "    # build dataframe\n",
    "    stats = pd.DataFrame({'Mean': [mean], 'Median': [median], 'Std Dev': [std_dev],\n",
    "                          'Skew': [skew], 'Kurtosis': [kurtosis]},\n",
    "                           index=[numerical_var])\n",
    "    return(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d04359f-f06c-4c5b-94cf-7df302d853f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_stats_by_category(data, numerical_var, categorical_var):\n",
    "    \"\"\"\n",
    "    Generate count, mean, std dev, and percentiles for a level of categorical var \n",
    "    (e.g. 'price by zipcode')\n",
    "\n",
    "    Args:\n",
    "        data (dataframe): the dataframe with the data\n",
    "        numerical_var (str): the 'level' of the categorical variable (you may use \n",
    "            this on hours, metro, and conversion)\n",
    "        categorical_var (str): the categorical variable you want stats for\n",
    "    \n",
    "    Returns:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    # grab data subset\n",
    "    filtered_data = data.groupby(categorical_var)[numerical_var]\n",
    "    stats = filtered_data.describe()\n",
    "\n",
    "    # add columns for skew and kurtosis\n",
    "    stats['Skew'] = filtered_data.apply(lambda x: x.skew())\n",
    "    stats['Kurtosis'] = filtered_data.apply(lambda x: x.kurtosis())\n",
    "\n",
    "    # reorganize\n",
    "    stats.drop(columns = ['count', 'min', '25%', '75%', 'max'], inplace = True)\n",
    "    stats.columns = ['Mean', 'Std Dev', 'Median', 'Skew', 'Kurtosis']\n",
    "    \n",
    "    return stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b705b288-9258-49da-a6cc-e4a16775f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_by_mean(data, categorical_var, numerical_var, start, end):\n",
    "    \"\"\"\n",
    "    Plot the mean of a continuous var for a categorical var (e.g. hours per metro)\n",
    "\n",
    "    Args:\n",
    "        data (dataframe)\n",
    "        categorical_var (str)\n",
    "        numerical_var (str)\n",
    "        start (int): start index to select categorical_vars\n",
    "        end (int): end index (non-inclusive)\n",
    "    \"\"\"\n",
    "    # sort data and grab requested subset\n",
    "    means = data.groupby(categorical_var)[numerical_var].mean()\n",
    "    means_sorted = means.sort_index(ascending = True)\n",
    "    subset = means_sorted.iloc[start:end]\n",
    "    \n",
    "    # create plot\n",
    "    plt.bar(subset.index, subset)\n",
    "    plt.xlabel(categorical_var)\n",
    "    plt.ylabel(f\"Mean {numerical_var}\")\n",
    "    plt.title(f\"Mean {numerical_var} by {categorical_var}\")\n",
    "\n",
    "    # format to make large data sets more readable\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9283262-a463-40c7-9767-99f84458a177",
   "metadata": {},
   "source": [
    "## Applications of Above Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd0ef74-8dd5-4166-bad5-6cf11b9283f7",
   "metadata": {},
   "source": [
    "Here are a few examples of the above functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9aa1ad-709c-4a03-bd63-3068f0ec92c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "continuous_stats(df, 'Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1d1a6-63a5-4ec5-95b5-ed5e8e0067f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_stats(df, 'Conversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc777b73-c71e-4080-953e-b279c09f1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_stats_by_category(df, 'Hours', 'OS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609a584-e60d-4ff6-9f49-163a255ec9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_stats_by_category(df, 'Conversion', 'Metro').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea20cd8-4058-41f8-bde2-4f45298834f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_by_mean(df, 'OS', 'Hours', 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53879b-2759-4746-a999-1c31dfc262d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_by_mean(df, 'Metro', 'Conversion', 1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fdfc4a-4872-4224-817c-00cda479b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_by_mean(df, 'Metro', 'Conversion', 30, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01def97a-00a8-460b-9ad9-cbb66525864c",
   "metadata": {},
   "source": [
    "# Data Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cff361-a06e-4f83-9eeb-1f04b1ff86a7",
   "metadata": {},
   "source": [
    "## Process and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd451b2f-c8e2-44bd-972b-dd15aa812425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature and target arrays\n",
    "X = df.drop('Conversion', axis=1)\n",
    "y = df[['Conversion']]\n",
    "\n",
    "# convert categorical variables to category type (instead of object)\n",
    "cat_vars = ['Site', 'Format', 'Browser', 'Vendor', 'Metro', 'OS']\n",
    "for c in cat_vars:\n",
    "    X[c] = X[c].astype('category')\n",
    "\n",
    "# split the data into train and test sets (default 0.25 test size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e09df3-c944-4705-860d-89570123d636",
   "metadata": {},
   "source": [
    "## Print Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a630769e-82e5-4ba3-a95f-68845dfa2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation(y_test, preds):\n",
    "    # ROC curve and ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    # convert predictions to binary to calculate remaining metrics\n",
    "    for index, item in enumerate(preds, start = 0):\n",
    "        preds[index] = item.round()\n",
    "        \n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    # accuracy, precision, recall, f1\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    \n",
    "    # print all stats\n",
    "    print('  MODEL METRICS')\n",
    "    print('-----------------')\n",
    "    print(f\"RMSE:      {rmse:.4f}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"ROC AUC:   {roc_auc:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # plotting ROC\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Pos Rate')\n",
    "    plt.ylabel('True Pos Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655cf05-f557-4344-a163-d3a7cf85206c",
   "metadata": {},
   "source": [
    "## Method 1: Using DMatrix in XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadcfc69-6133-427c-8995-5a416da6b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to DMatrix format\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical = True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical = True)\n",
    "\n",
    "# define parameters (note that conversion is binary)\n",
    "params = {\"objective\": \"binary:logistic\", \"tree_method\": \"hist\"}\n",
    "\n",
    "# train\n",
    "model = xgb.train(params = params, dtrain = dtrain_reg, num_boost_round = 100)\n",
    "\n",
    "# predict\n",
    "preds = model.predict(dtest_reg)\n",
    "\n",
    "# evaluate the model\n",
    "print_evaluation(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65396ee4-2dcd-413d-b5d6-d79c046cde68",
   "metadata": {},
   "source": [
    "## Analysis of DMatrix Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03806e94-6f7f-4a4e-bb5a-9811447c8673",
   "metadata": {},
   "source": [
    "This model is successful overall; it is able to accurately classify around 84% of the data set. The high ROC AUC demonstrates that the model can accurately distinguish between positive and negative instances. However, its largest weakness is the recall metric, implying that the model struggles to identify all cases of conversion. As a result, applying this model means that not all conversion opportunities are identified and thus fewer potential customers are targeted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca6390-8f8e-4d8f-b7c0-2feddcae8bc6",
   "metadata": {},
   "source": [
    "## Method 2: Using GridSearchCV from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90646fbf-98af-46d2-84b0-60ad5abe20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify constants\n",
    "estimator = XGBClassifier(\n",
    "    objective = 'binary:logistic',\n",
    "    nthread = 4,\n",
    "    seed = 42,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "# set tunable parameters (Note: I could not do a large amount of tuning on my laptop)\n",
    "parameters = {\n",
    "    'max_depth': [3, 5],\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.1, 0.05]\n",
    "}\n",
    "\n",
    "# perform grid search; compare hyperparameters based on ROC AUC\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = parameters,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = -1,\n",
    "    cv = 5\n",
    ")\n",
    "\n",
    "# train\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ebe82-184c-406a-8904-7c82647a7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print('    PARAMETERS')\n",
    "print('------------------')\n",
    "print(f\"Learning Rate: {best_params['learning_rate']}\")\n",
    "print(f\"Max Depth:     {best_params['max_depth']}\")\n",
    "print(f\"N Estimators:  {best_params['n_estimators']}\")\n",
    "print()\n",
    "\n",
    "# save best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# predict\n",
    "preds = best_estimator.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print_evaluation(y_test, preds)\n",
    "\n",
    "# feature importances\n",
    "feature_importances = best_estimator.feature_importances_\n",
    "\n",
    "print()\n",
    "print('  FEATURE IMPORTANCES')\n",
    "print('-----------------------')\n",
    "\n",
    "plt.bar(['Site', 'Format', 'Browser', 'Vendor', 'Metro', 'OS', 'Hours'], feature_importances)\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69f1a7-ec70-42c6-984d-c64f62a350f4",
   "metadata": {},
   "source": [
    "## Analysis of GridSearchCV Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21ca47-e26a-477f-a570-431843183a6f",
   "metadata": {},
   "source": [
    "The GridSearchCV Model performed similarly to the DMatrix Model, but the recall was slightly worse. This model could be more effective if the grid search consisted of more parameter values. With this model, I was able to look at feature importances, which yielded that the browser had significantly more impact on the model's output. Different browsers offer varying user experiences -- for example, browser features such as speed, security, and ad-blocking vary and could impact the conversion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666cf77-8943-4938-9243-03ac68e35923",
   "metadata": {},
   "source": [
    "## Additional Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51c82d-28aa-4647-abbf-a63606860be8",
   "metadata": {},
   "source": [
    "Data suitability could be improved by adding more information on user demographics and product types. For example, the websites provided could be sorted based on category (e.g. online clothing shopping, online games) in order to better assess what websites the target demographic would be on. It would also be extremely useful to include data on the users themselves and whether they had prior exposure to the company's products."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
